{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from plotly.offline import iplot\n",
    "import plotly.graph_objs as go\n",
    "import numpy as np\n",
    "from sklearn import metrics\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import defaultdict\n",
    "from functools import partial\n",
    "from itertools import repeat\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from keras.utils import to_categorical\n",
    "from keras import models\n",
    "from keras import layers\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from keras.layers import Dense, Dropout, Activation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/llavezzo/.local/lib/python3.6/site-packages/ipykernel_launcher.py:19: FutureWarning:\n",
      "\n",
      "Method .as_matrix will be removed in a future version. Use .values instead.\n",
      "\n",
      "/home/llavezzo/.local/lib/python3.6/site-packages/ipykernel_launcher.py:20: FutureWarning:\n",
      "\n",
      "Method .as_matrix will be removed in a future version. Use .values instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "workDir = \"/mnt/c/Users/llave/Documents/nBody/\"\n",
    "\n",
    "#Import data\n",
    "fname = workDir + \"data/batch_brutus10_4.csv\"\n",
    "df = pd.read_csv(fname)\n",
    "with pd.option_context('mode.use_inf_as_null', True):\n",
    "    df = df.dropna()\n",
    "\n",
    "acc_list = []\n",
    "loss_list = []\n",
    "iterations_list = []\n",
    "nodes_list = [128]\n",
    "\n",
    "#dfShuffle = shuffle(df,random_state=42)\n",
    "i_col = [\"m1\",\"m2\",\"m3\",\"x1\", \"x2\", \"x3\", \"y1\", \"y2\", \"y3\",\n",
    "    \"dx1\",\"dx2\",\"dx3\",\"dy1\",\"dy2\",\"dy3\",\"tEnd\"]\n",
    "o_col = [\"x1tEnd\", \"x2tEnd\", \"x3tEnd\", \"y1tEnd\", \"y2tEnd\", \"y3tEnd\",\n",
    "         \"dx1tEnd\", \"dx2tEnd\", \"dx3tEnd\", \"dy1tEnd\", \"dy2tEnd\", \"dy3tEnd\"]\n",
    "X = df.as_matrix(columns=i_col)\n",
    "y = df.as_matrix(columns=o_col)\n",
    "\n",
    "X = X.astype('float64')\n",
    "y = y.astype('float64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nested_defaultdict(default_factory, depth=1):\n",
    "    result = partial(defaultdict, default_factory)\n",
    "    for _ in repeat(None, depth - 1):\n",
    "        result = partial(defaultdict, result)\n",
    "    return result()    \n",
    "\n",
    "def kfold_network(X, y, hidden_nodes,activation='relu',optimizer='adam'):\n",
    "\n",
    "    max_epochs = 300\n",
    "    \n",
    "    numSplits = 0\n",
    "    \n",
    "    network = models.Sequential()\n",
    "    network.add(layers.Dense(hidden_nodes,activation='relu',input_dim=16))\n",
    "    for i in range(9):\n",
    "        network.add(layers.Dense(128,activation='relu'))\n",
    "    network.add(layers.Dense(12,activation='linear'))\n",
    "    network.compile(optimizer=optimizer,loss='mean_squared_logarithmic_error',metrics=['accuracy'])\n",
    "    network.save_weights(workDir + '/weights/model_init.h5')\n",
    "    \n",
    "    #early stopping\n",
    "    patienceCount = 20\n",
    "    callbacks = [EarlyStopping(monitor='val_loss', patience=patienceCount),\n",
    "                 ModelCheckpoint(filepath=workDir+'/weights/best_model_split'+str(numSplits)+'_nhidden'+str(hidden_nodes)+'.h5', monitor='val_loss', save_best_only=True)]\n",
    "\n",
    "    #k-fold validation with 4 folds\n",
    "    kfolds = 4\n",
    "    \n",
    "    training_vals_acc = 0\n",
    "    training_vals_loss = 0\n",
    "    valid_vals_acc = 0\n",
    "    valid_vals_loss = 0\n",
    "    iterations = 0\n",
    "    \n",
    "    avg_acc = 0\n",
    "    avg_loss = 0\n",
    "    avg_iterations = 0\n",
    "\n",
    "    #k-fold validation with 5 folds\n",
    "    kfolds = 5\n",
    "    skf = KFold(n_splits=kfolds)\n",
    "\n",
    "    for train_index, val_index in skf.split(X, y):\n",
    "\n",
    "        print(\"Training on numSplit:\",numSplits)\n",
    "        numSplits += 1\n",
    "        X_train = X[train_index]\n",
    "        y_train = y[train_index]\n",
    "        X_val = X[val_index]\n",
    "        y_val = y[val_index]\n",
    "\n",
    "        network.load_weights(workDir + '/weights/model_init.h5')\n",
    "        history = network.fit(X_train,y_train,\n",
    "                              callbacks = callbacks,\n",
    "                              epochs=max_epochs,\n",
    "                              batch_size=1000,\n",
    "                              validation_data=(X_val,y_val), \n",
    "                              verbose = 1)\n",
    "        \n",
    "        network.save(workDir + '/weights/trained_model_split'+str(numSplits)+'_nhidden'+str(hidden_nodes)+'.h5')\n",
    "\n",
    "        plt.clf()\n",
    "        plt.plot(history.history['accuracy'])\n",
    "        plt.plot(history.history['val_accuracy'])\n",
    "        plt.savefig(workDir + '/plots/nodes'+str(hidden_nodes)+'_split'+str(numSplits)+'_accuracy.png')\n",
    "        \n",
    "        #save the metrics for the best epoch, or the last one\n",
    "        if(len(history.history['accuracy']) == max_epochs):\n",
    "            iterations += max_epochs\n",
    "            training_vals_acc += history.history['accuracy'][max_epochs-1]\n",
    "            training_vals_loss += history.history['loss'][max_epochs-1]\n",
    "            valid_vals_acc += history.history['val_accuracy'][max_epochs-1]\n",
    "            valid_vals_loss += history.history['val_loss'][max_epochs-1]\n",
    "        else:\n",
    "            iterations += len(history.history['accuracy']) - 10\n",
    "            i = len(history.history['accuracy']) - 10 - 1\n",
    "            training_vals_acc += history.history['accuracy'][i]\n",
    "            training_vals_loss += history.history['loss'][i]\n",
    "            valid_vals_acc += history.history['val_accuracy'][i]\n",
    "            valid_vals_loss += history.history['val_loss'][i]\n",
    "           \n",
    "        \t\n",
    "    training_vals_acc /= numSplits\n",
    "    training_vals_loss /= numSplits\n",
    "    valid_vals_acc /= numSplits\n",
    "    valid_vals_loss /= numSplits\n",
    "    iterations /= numSplits*1.0\n",
    "\n",
    "    avg_acc = valid_vals_acc\n",
    "    avg_loss = valid_vals_loss\n",
    "    avg_iterations = iterations\n",
    "    \n",
    "\n",
    "    # Return the average accuracy and loss and iterations (on the validation sample!)\n",
    "    return avg_acc,avg_loss, avg_iterations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training:\n",
      "Nodes: 128\n",
      "Training on numSplit: 0\n",
      "Train on 742632 samples, validate on 185658 samples\n",
      "Epoch 1/300\n",
      "644000/742632 [=========================>....] - ETA: 0s - loss: 0.2624 - accuracy: 0.5389"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-64-d6254432557e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0;31m#run train data through the network\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m     \u001b[0mavg_acc\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mavg_loss\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mavg_iterations\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkfold_network\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnodes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0;31m#store and output results\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-63-253e0fe1cd0c>\u001b[0m in \u001b[0;36mkfold_network\u001b[0;34m(X, y, hidden_nodes, activation, optimizer)\u001b[0m\n\u001b[1;32m     56\u001b[0m                               \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1000\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m                               \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_val\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_val\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 58\u001b[0;31m                               verbose = 1)\n\u001b[0m\u001b[1;32m     59\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m         \u001b[0mnetwork\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mworkDir\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'/weights/trained_model_split'\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnumSplits\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'_nhidden'\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_nodes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'.h5'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m   1237\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1238\u001b[0m                                         \u001b[0mvalidation_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_steps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1239\u001b[0;31m                                         validation_freq=validation_freq)\n\u001b[0m\u001b[1;32m   1240\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1241\u001b[0m     def evaluate(self,\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[0;34m(model, fit_function, fit_inputs, out_labels, batch_size, epochs, verbose, callbacks, val_function, val_inputs, shuffle, initial_epoch, steps_per_epoch, validation_steps, validation_freq)\u001b[0m\n\u001b[1;32m    194\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    195\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 196\u001b[0;31m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfit_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    197\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow/python/keras/backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   3290\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3291\u001b[0m     fetched = self._callable_fn(*array_vals,\n\u001b[0;32m-> 3292\u001b[0;31m                                 run_metadata=self.run_metadata)\n\u001b[0m\u001b[1;32m   3293\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_fetch_callbacks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3294\u001b[0m     output_structure = nest.pack_sequence_as(\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1456\u001b[0m         ret = tf_session.TF_SessionRunCallable(self._session._session,\n\u001b[1;32m   1457\u001b[0m                                                \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1458\u001b[0;31m                                                run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1459\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1460\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Determine best number of hidden nodes for one charge, and apply it for other charges\n",
    "for nodes in nodes_list:\n",
    "    \n",
    "    print(\"Training:\")\n",
    "    print(\"Nodes:\", nodes)\n",
    "    \n",
    "    #run train data through the network\n",
    "    avg_acc,avg_loss,avg_iterations = kfold_network(X, y, nodes)\n",
    "    \n",
    "    #store and output results\n",
    "    acc_list.append(avg_acc)\n",
    "    loss_list.append(avg_loss)\n",
    "    iterations_list.append(avg_iterations)\n",
    "    \n",
    "    print(avg_acc, avg_loss, avg_iterations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.clf()\n",
    "plt.plot(nodes_list,acc_list)\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Number of Hidden Nodes')\n",
    "plt.savefig(workDir+\"/plots/accuracy_nodes.png\")\n",
    "\n",
    "plt.clf()\n",
    "plt.plot(nodes_list,loss_list)\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Number of Hidden Nodes')\n",
    "plt.savefig(workDir+\"/plots/loss_nodes.png\")\n",
    "\n",
    "plt.clf()\n",
    "plt.plot(nodes_list,iterations_list)\n",
    "plt.ylabel('Iterations (Epochs)')\n",
    "plt.xlabel('Number of Hidden Nodes')\n",
    "plt.savefig(workDir+\"/plots/iterations_nodes.png\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (flow)",
   "language": "python",
   "name": "flow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
